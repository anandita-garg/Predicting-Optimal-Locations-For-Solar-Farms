{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnlKAJT8St1Y8X1A8Enxjm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandita-garg/Predicting-Optimal-Locations-For-Solar-Farms/blob/main/year_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "csvs used:\n",
        "\n",
        "1. filtered_output= solar points from scaredcat\n",
        "2. india_sf= points from Global-Solar-Power-Tracker dataset that are from india\n",
        "3. solar_farms.csv= all solar farms found from old dataset\n",
        "4. unique_best_matches_within_5km= all matches with Global-Solar-Power-Tracker and old dataset\n",
        "5. updated_unique_best_matches= update with year + if it is in scared cat or not\n",
        "6. final_unique_best_matches= dropped null year rows.\n",
        "7. scared cat= dataset with coordinates of different locations, including both solar farm and non solar farm coordinates, with their respective features extracted"
      ],
      "metadata": {
        "id": "SNnNQxst9ziG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXGfThLNUxXU"
      },
      "outputs": [],
      "source": [
        "#get all solar locations from scared cat file, essentially extract rows where suitability score =1\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('ScaredCAT.csv')\n",
        "filtered_df = df[df['Suitability Score'] == 1]\n",
        "\n",
        "filtered_df.to_csv('filtered_output.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# minimize total distance and maximize unique matches using Hungarian Algorithm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from geopy.distance import geodesic\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "# Load data\n",
        "df_india = pd.read_excel(\"india_sf.xlsx\")\n",
        "df_cat = pd.read_csv('solarfarms.csv')\n",
        "\n",
        "# Build distance matrix\n",
        "n_india = len(df_india)\n",
        "n_cat = len(df_cat)\n",
        "\n",
        "distance_matrix = np.zeros((n_india, n_cat))\n",
        "\n",
        "for i, row_india in df_india.iterrows():\n",
        "    for j, row_cat in df_cat.iterrows():\n",
        "        dist = geodesic(\n",
        "            (row_india['Latitude'], row_india['Longitude']),\n",
        "            (row_cat['latitude'], row_cat['longitude'])\n",
        "        ).km\n",
        "        distance_matrix[i, j] = dist\n",
        "\n",
        "# Solve for minimizing total distance with unique matches\n",
        "row_ind, col_ind = linear_sum_assignment(distance_matrix)\n",
        "\n",
        "# Filter matches with distance < 5 km\n",
        "matches = []\n",
        "for i, j in zip(row_ind, col_ind):\n",
        "    dist = distance_matrix[i, j]\n",
        "    if dist < 5:\n",
        "        matches.append({\n",
        "            'India_Latitude': df_india.loc[i, 'Latitude'],\n",
        "            'India_Longitude': df_india.loc[i, 'Longitude'],\n",
        "            'ClosestCAT_Latitude': df_cat.loc[j, 'latitude'],\n",
        "            'ClosestCAT_Longitude': df_cat.loc[j, 'longitude'],\n",
        "            'Distance_km': round(dist, 3)\n",
        "        })\n",
        "\n",
        "# Save to Excel\n",
        "matched_df = pd.DataFrame(matches)\n",
        "matched_df.to_excel(\"unique_best_matches_within_5km.xlsx\", index=False)\n",
        "\n",
        "print(f\"{len(matched_df)} unique matches saved to 'unique_best_matches_within_5km.xlsx'\")"
      ],
      "metadata": {
        "id": "hA2BkJG_siXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the number of points that overlap betwwen the scared cat dataset and the best matches dataset.\n",
        "# This is to see how many solar farm coordinates do we already have the features for\n",
        "\n",
        "# Load CSVs\n",
        "india_sf = pd.read_excel(\"india_sf.xlsx\")\n",
        "filtered_output = pd.read_csv('filtered_output.csv')\n",
        "unique_best_matches = pd.read_excel('unique_best_matches_within_5km.xlsx')\n",
        "\n",
        "# Round coordinates for consistent matching\n",
        "for df in [india_sf, filtered_output]:\n",
        "    df['Latitude'] = df['Latitude'].round(6)\n",
        "    df['Longitude'] = df['Longitude'].round(6)\n",
        "\n",
        "unique_best_matches['ClosestCAT_Latitude'] = unique_best_matches['ClosestCAT_Latitude'].round(6)\n",
        "unique_best_matches['ClosestCAT_Longitude'] = unique_best_matches['ClosestCAT_Longitude'].round(6)\n",
        "unique_best_matches['India_Latitude'] = unique_best_matches['India_Latitude'].round(6)\n",
        "unique_best_matches['India_Longitude'] = unique_best_matches['India_Longitude'].round(6)\n",
        "\n",
        "filtered_coords = set(zip(filtered_output['Latitude'], filtered_output['Longitude']))\n",
        "\n",
        "# Mark \"1\" if the lat-long in unique_best_matches is found in filtered_output\n",
        "unique_best_matches['in scared cat'] = unique_best_matches.apply(\n",
        "    lambda row: 1 if (row['ClosestCAT_Latitude'], row['ClosestCAT_Longitude']) in filtered_coords else 0,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Fill in the years for all the solar farm coordinates\n",
        "merged_year = unique_best_matches.merge(\n",
        "    india_sf[['Latitude', 'Longitude', 'Start year']],\n",
        "    left_on=['India_Latitude', 'India_Longitude'],\n",
        "    right_on=['Latitude', 'Longitude'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "unique_best_matches['year'] = merged_year['Start year']\n",
        "\n",
        "# Final dataset\n",
        "unique_best_matches.to_csv('updated_unique_best_matches.csv', index=False)\n",
        "\n",
        "total_overlap = unique_best_matches['in scared cat'].sum()\n",
        "print(f\"Total number of overlapping points with filtered_output: {total_overlap}\")\n"
      ],
      "metadata": {
        "id": "_27J35ZayqYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check which coordinates have missing years\n",
        "df = pd.read_csv('updated_unique_best_matches.csv')\n",
        "missing_years = df['year'].isnull() | (df['year'].astype(str).str.strip() == '')\n",
        "\n",
        "num_missing = missing_years.sum()\n",
        "print(f\"Number of rows with missing/blank/empty 'year': {num_missing}\")\n"
      ],
      "metadata": {
        "id": "8b-UGfF40mki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('updated_unique_best_matches.csv')\n",
        "\n",
        "# Drop rows where 'year' is null/blank/empty\n",
        "df_cleaned = df[~(df['year'].isnull() | (df['year'].astype(str).str.strip() == ''))]\n",
        "\n",
        "df_cleaned.to_csv('final_unique_best_matches.csv', index=False)\n",
        "\n",
        "in_scared_cat_count = df_cleaned['in scared cat'].sum()\n",
        "\n",
        "print(f\"Cleaned CSV saved as 'final_unique_best_matches.csv'\")\n",
        "print(f\"Number of rows where 'in scared cat' == 1: {in_scared_cat_count}\")\n"
      ],
      "metadata": {
        "id": "j2stylEw2HNM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}